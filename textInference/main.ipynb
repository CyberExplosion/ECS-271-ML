{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may choose to experiment with different methods using your program. However, you need to embed the training and inference processes at here. We will use your prediction on the unlabeled test data to grade, while checking this part to understand how your method has produced the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model, checkpointPath):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, checkpointPath)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, checkpointPath)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, savePath):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), savePath)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class RunBuilder:\n",
    "    def __init__(self, params) -> None:\n",
    "        self.runs = self._get_runs(params)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.runs)\n",
    "\n",
    "    def _get_runs(self, params):\n",
    "        Run = namedtuple(\"Run\", params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            # print(f\"value {v} and {Run(*v)}\")\n",
    "            runs.append(Run(*v))\n",
    "        return runs\n",
    "\n",
    "\n",
    "class RunManager:\n",
    "    def __init__(self, statsFolderPath, statsFileName, earlyStop=True):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_train_loss = 0\n",
    "        self.epoch_valid_loss = 0\n",
    "        self.epoch_numTrain_correct = 0\n",
    "        self.epoch_numValid_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.model = None\n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "        self.tb = None\n",
    "\n",
    "        self.useEarlyStop = earlyStop\n",
    "        self.earlyStop = None\n",
    "        self.stop = False\n",
    "\n",
    "        self.statsFolderPath = Path(statsFolderPath)\n",
    "        Path.mkdir(self.statsFolderPath, exist_ok=True, parents=True)\n",
    "        self.statsFileCSV = Path(self.statsFolderPath, f\"{statsFileName}.csv\")\n",
    "        self.errorPath = Path(statsFolderPath, \"error.txt\")\n",
    "        open(self.errorPath, \"w\")  # restart the error file\n",
    "\n",
    "    def begin_run(self, run, model, trainLoader, validLoader):\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.model = model\n",
    "        self.train_loader = trainLoader\n",
    "        self.valid_loader = validLoader\n",
    "        comment = f\"-{ {k: v if k != 'model' else v.__class__.__name__ for k,v in run._asdict().items()} }\"\n",
    "        self.tb = SummaryWriter(comment=self.sanitize_param_name(comment))\n",
    "\n",
    "        if self.run_count == 1:\n",
    "            self.tb.add_graph(self.model, next(iter(self.train_loader))[0].to(self.model.device), use_strict_trace=False)\n",
    "        # images, labels = next(iter(self.train_loader))\n",
    "        # grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        # self.tb.add_image(\"images\", grid)  # Add images and graph when begin one run\n",
    "        self.earlyStop = EarlyStopping()\n",
    "        self.stop = False\n",
    "\n",
    "    def end_run(self, savePath=\"\", save=False):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "        self.writeToCSV()\n",
    "        if save:\n",
    "            self.saveModel(savePath, result=self.run_data[-1])\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_train_loss = 0\n",
    "        self.epoch_numTrain_correct = 0\n",
    "        self.epoch_valid_loss = 0\n",
    "        self.epoch_numValid_correct = 0\n",
    "\n",
    "    def end_epoch(self, checkptFolderPath):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        train_loss = self.epoch_train_loss / len(self.train_loader.dataset)\n",
    "        train_accuracy = self.epoch_numTrain_correct / len(self.train_loader.dataset)\n",
    "\n",
    "        valid_loss = self.epoch_valid_loss / len(self.valid_loader.dataset)\n",
    "        valid_accuracy = self.epoch_numValid_correct / len(self.valid_loader.dataset)\n",
    "\n",
    "        self.tb.add_scalars(\n",
    "            \"Loss\", {\"trainLoss\": train_loss, \"validLoss\": valid_loss}, self.epoch_count\n",
    "        )\n",
    "        self.tb.add_scalars(\n",
    "            \"Accuracy\",\n",
    "            {\"trainAcc\": train_accuracy, \"validAcc\": valid_accuracy},\n",
    "            self.epoch_count,\n",
    "        )  # Add scalar is use when at the end of epoch\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            if param.grad != None:\n",
    "                self.tb.add_histogram(f\"{name}.grad\", param.grad, self.epoch_count)\n",
    "\n",
    "        results = {}\n",
    "        results[\"run\"] = self.run_count\n",
    "        results['model name'] = self.run_params.model.__class__.__name__\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"train loss\"] = train_loss\n",
    "        results[\"valid loss\"] = valid_loss\n",
    "        results[\"train accuracy\"] = train_accuracy\n",
    "        results[\"valid accuracy\"] = valid_accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "        for k, v in self.run_params._asdict().items():\n",
    "            if (k != 'model'):\n",
    "                results[k] = v  # Add the hyperparameter to words to easy report\n",
    "        self.run_data.append(results)\n",
    "        if self.useEarlyStop:\n",
    "            self.checkEarlyStop(\n",
    "                valid_loss, self.model, checkptFolderPath, self.run_count\n",
    "            )\n",
    "            if self.earlyStop.early_stop:\n",
    "                self.stop = True\n",
    "\n",
    "        # print(f'Current run data: {self.run_data}')\n",
    "\n",
    "    def track_train_loss(self, loss):\n",
    "        self.epoch_train_loss += loss.item() * self.train_loader.batch_size\n",
    "\n",
    "    def track_valid_loss(self, loss):\n",
    "        self.epoch_valid_loss += loss.item() * self.valid_loader.batch_size\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "    def track_numTrain_correct(self, preds, labels):\n",
    "        self.epoch_numTrain_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "    def track_numValid_correct(self, preds, labels):\n",
    "        self.epoch_numValid_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "    def checkEarlyStop(self, valLoss, model, folderPath, run):\n",
    "        fPath = Path(folderPath)\n",
    "        Path.mkdir(fPath, exist_ok=True, parents=True)\n",
    "        filePath = Path(fPath / f\"earlyStop_run_{run}.pt\")\n",
    "\n",
    "        self.earlyStop(valLoss, model, filePath)\n",
    "\n",
    "    def saveModel(self, pathName, result):\n",
    "        moduleName = \"\"\n",
    "        for k, v in result.items():\n",
    "            if (k == 'epoch' or k == 'run' or k == 'epoch' or k == 'model name' or k == 'train loss' or k == 'valid loss' or k == 'train accuracy' or k == 'valid accuracy'):\n",
    "                moduleName += f\"_{k}:{v}\"\n",
    "        folderPath = Path(pathName)\n",
    "        Path.mkdir(folderPath, exist_ok=True, parents=True)\n",
    "        filePath = Path(folderPath / f\"{self.sanitize_param_name(moduleName)}.pt\")\n",
    "        torch.save(self.model.state_dict(), filePath)\n",
    "\n",
    "    def writeError(self, msg=\"\"):\n",
    "        with open(self.errorPath, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"Error at runs: {self.run_count}\\nParameters: {self.run_params}\\nAdditional msg: {msg}\"\n",
    "            )\n",
    "\n",
    "    def writeToCSV(self):\n",
    "        oldStatsDF = None\n",
    "        # print(f\"The stats file is {self.statsFileCSV}\")\n",
    "        try:\n",
    "            with open(self.statsFileCSV, \"r\") as f:\n",
    "                oldStatsDF = pd.read_csv(f)\n",
    "                oldStatsDF = pd.concat(\n",
    "                    [\n",
    "                        oldStatsDF,\n",
    "                        pd.DataFrame.from_records(self.run_data[-1], index=[0]),\n",
    "                    ]\n",
    "                )\n",
    "        except FileNotFoundError:\n",
    "            oldStatsDF = pd.DataFrame.from_dict(self.run_data)\n",
    "\n",
    "        try:\n",
    "            # Allow open file in create mode and write the new data\n",
    "            with open(self.statsFileCSV, \"w\", newline=\"\") as f:\n",
    "                oldStatsDF.to_csv(f, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in writeToCSV: {e}\")\n",
    "            self.writeError(f\"Error in writeToCSV: {e}\")\n",
    "\n",
    "    def sanitize_param_name(self, param_name):\n",
    "        return (\n",
    "            param_name.replace(\"(\", \"\")\n",
    "            .replace(\")\", \"\")\n",
    "            .replace(\",\", \"_\")\n",
    "            .replace(\" \", \"_\")\n",
    "            .replace(\"<\", \"\")\n",
    "            .replace(\">\", \"\")\n",
    "            .replace(\"'\", \"\")\n",
    "            .replace(\":\", \"\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Maybe incorporate loading into embedding\n",
    "\n",
    "DATAFOLDER = \"../data\"\n",
    "TOKEN_FOLDER = \"./tokenized\"\n",
    "\n",
    "\n",
    "class PreconditionStatementDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, type=\"train\") -> None:\n",
    "        self.data = pd.read_csv(DATAFOLDER + f\"/pnli_{type}.csv\", header=None)\n",
    "        self.dataset_type: str = type\n",
    "        self.tokenized_data: List[Tuple[torch.Tensor, int]] = []\n",
    "\n",
    "        tokenized_file = f\"{TOKEN_FOLDER}/pnli_{self.dataset_type}_tokenized.pt\"\n",
    "\n",
    "        if os.path.exists(tokenized_file):\n",
    "            self.tokenized_data = torch.load(tokenized_file)\n",
    "        else:\n",
    "            self.tokenized_data = self.tokenize_and_save(tokenized_file, type)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        if self.dataset_type == \"test_unlabeled\":\n",
    "            tokens = self.tokenized_data[idx]\n",
    "            return torch.tensor(tokens)\n",
    "        else:\n",
    "            tokens, label = self.tokenized_data[idx]\n",
    "            return torch.tensor(tokens), torch.tensor(label)\n",
    "\n",
    "    def tokenize_and_save(self, tokenize_file, type) -> List[Tuple[torch.Tensor, int]]:\n",
    "        tokenized_data = []\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large-mnli\")\n",
    "        for _, row in tqdm(\n",
    "            self.data.iterrows(), \"Tokenizing data\", total=self.data.shape[0]\n",
    "        ):\n",
    "            if type == \"test_unlabeled\":\n",
    "                precondition, statement = row\n",
    "                tokenized_data.append(\n",
    "                    (tokenizer.encode(str(precondition), str(statement)))\n",
    "                )\n",
    "            else:\n",
    "                precondition, statement, label = row\n",
    "                tokenized_data.append(\n",
    "                    (tokenizer.encode(str(precondition), str(statement)), int(label))\n",
    "                )\n",
    "        torch.save(tokenized_data, tokenize_file)\n",
    "        return tokenized_data\n",
    "\n",
    "    def custom_collate_fn(self, batch):\n",
    "        if self.dataset_type == \"test_unlabeled\":\n",
    "            tokens_batch = [tokens for tokens in batch]\n",
    "            max_length = max([len(tokens) for tokens in tokens_batch])\n",
    "            tokens_batch = [\n",
    "                torch.nn.functional.pad(tokens, (0, max_length - len(tokens)))\n",
    "                for tokens in tokens_batch\n",
    "            ]\n",
    "            return torch.stack(tokens_batch)\n",
    "        else:\n",
    "            tokens_batch, labels_batch = zip(*batch)\n",
    "            max_length = max([len(tokens) for tokens in tokens_batch])\n",
    "            tokens_batch = [\n",
    "                torch.nn.functional.pad(tokens, (0, max_length - len(tokens)))\n",
    "                for tokens in tokens_batch\n",
    "            ]\n",
    "            return torch.stack(tokens_batch), torch.tensor(labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange\n",
    "from transformers import RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large-mnli and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([2, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "SAVE_MODEL_PATH = \"./savedModels\"\n",
    "STATISTIC_PATH = \"./savedStatistics\"\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "params = OrderedDict(\n",
    "    epoch=[100],\n",
    "    lr=[0.000001],\n",
    "    model=[\n",
    "        RobertaForSequenceClassification.from_pretrained(\n",
    "            \"FacebookAI/roberta-large-mnli\", num_labels=2, ignore_mismatched_sizes=True\n",
    "        )\n",
    "    ],\n",
    "    optim=[torch.optim.Adam],\n",
    "    criterion=[torch.nn.CrossEntropyLoss],\n",
    "    batch_size=[32],\n",
    "    num_worker=[0],\n",
    "    num_layers_to_unfreeze=[6],\n",
    ")\n",
    "\n",
    "\n",
    "class Train:\n",
    "    def freeze_roberta_layers_modified_layers(self, model, num_layers_to_unfreeze=0):\n",
    "        # Freeze the embedding layer\n",
    "        for layer in model.roberta.embeddings.parameters():\n",
    "            layer.requires_grad = False\n",
    "        model.roberta.embeddings.eval()  # Set to eval mode to avoid BatchNorm and Dropout layers to update their running stats\n",
    "        # Freeze the encoder layers\n",
    "        total_layers = len(model.roberta.encoder.layer)\n",
    "        for i, layers in enumerate(model.roberta.encoder.layer):\n",
    "            if i < total_layers - num_layers_to_unfreeze:\n",
    "                for params in layers.parameters():\n",
    "                    params.requires_grad = False\n",
    "                layers.eval()  # Set to eval mode to avoid BatchNorm and Dropout layers to update their running stats\n",
    "            else:\n",
    "                layers.requires_grad = True\n",
    "\n",
    "        # unfreeze classifier layer\n",
    "        for params in model.classifier.parameters():\n",
    "            params.requires_grad = True\n",
    "\n",
    "    def __init__(self, params, trainData: Dataset, devData: Dataset) -> None:\n",
    "        self.manager = RunManager(STATISTIC_PATH, TIMESTAMP)\n",
    "        self.runBuilder = RunBuilder(params)\n",
    "        self.trainData = trainData\n",
    "        self.devData = devData\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        self.model = RobertaForSequenceClassification.from_pretrained(\n",
    "            \"FacebookAI/roberta-large-mnli\", num_labels=2, ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        for k, run in enumerate(self.runBuilder.runs):\n",
    "            model = self.model.to(self.device)\n",
    "            train_loader = DataLoader(\n",
    "                self.trainData,\n",
    "                batch_size=run.batch_size,\n",
    "                num_workers=run.num_worker,\n",
    "                collate_fn=self.trainData.custom_collate_fn,\n",
    "                shuffle=True,\n",
    "            )\n",
    "            dev_loader = DataLoader(\n",
    "                self.devData,\n",
    "                batch_size=run.batch_size,\n",
    "                num_workers=run.num_worker,\n",
    "                collate_fn=self.devData.custom_collate_fn,\n",
    "                shuffle=False,\n",
    "            )\n",
    "            criterion = run.criterion()\n",
    "            optimizer = run.optim(\n",
    "                model.parameters(),\n",
    "                lr=run.lr,\n",
    "                betas=(0.9, 0.98),\n",
    "                eps=1e-6,\n",
    "                weight_decay=0.01,\n",
    "            )\n",
    "\n",
    "            total_steps = len(train_loader) * run.epoch\n",
    "            warmup_steps = int(0.1 * total_steps)\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    "            )\n",
    "\n",
    "            self.manager.begin_run(run, run.model, train_loader, dev_loader)\n",
    "            for _ in trange(run.epoch, desc=\"Epoch progress\"):\n",
    "                self.manager.begin_epoch()\n",
    "                model.train()  # Need to set before modify the layers inside the model\n",
    "                self.freeze_roberta_layers_modified_layers(\n",
    "                    model, run.num_layers_to_unfreeze\n",
    "                )  # freeze some layers\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(inputs).logits\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                    scheduler.step()\n",
    "                    self.manager.track_train_loss(loss)\n",
    "                    self.manager.track_numTrain_correct(outputs, labels)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for dev_inputs, dev_labels in dev_loader:\n",
    "                        # for _, (dev_inputs, dev_labels) in enumerate(tqdm(dev_loader, desc=\"Evaluation progress\")):\n",
    "                        dev_inputs, dev_labels = (\n",
    "                            dev_inputs.to(self.device),\n",
    "                            dev_labels.to(self.device),\n",
    "                        )\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            dev_outputs = model(dev_inputs).logits\n",
    "                            dev_loss = criterion(dev_outputs, dev_labels)\n",
    "                        self.manager.track_valid_loss(dev_loss)\n",
    "                        self.manager.track_numValid_correct(dev_outputs, dev_labels)\n",
    "                self.manager.end_epoch(SAVE_MODEL_PATH)\n",
    "                if self.manager.stop:\n",
    "                    break\n",
    "            self.manager.end_run(SAVE_MODEL_PATH, save=True)\n",
    "\n",
    "    def predict(self):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        testDataset = PreconditionStatementDataset(\"test_unlabeled\")\n",
    "        test_loader = DataLoader(\n",
    "            testDataset,\n",
    "            batch_size=1,\n",
    "            num_workers=0,\n",
    "            collate_fn=testDataset.custom_collate_fn,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for inputs in test_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = self.model(inputs).logits\n",
    "                predictions.append(torch.argmax(outputs, dim=1).item())\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large-mnli and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([2, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch progress:   0%|          | 0/100 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31391/230065738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreconditionStatementDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31391/1890889128.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Eventually, results need to be a list of 2028 0 or 1's\n",
    "trainDataset = PreconditionStatementDataset('train')\n",
    "devDataset = PreconditionStatementDataset('dev')\n",
    "trainer = Train(params, trainDataset, devDataset)\n",
    "trainer.run()\n",
    "results = trainer.predict()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Prediction Result File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to submit a prediction result file. It should have 2028 lines, every line should be either 0 or 1, which is your model's prediction on the respective test set instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose you had your model's predictions on the 2028 test cases read from test_enc_unlabeled.tsv, and \n",
    "#those results are in the list called 'results'\n",
    "assert (len(results) == 4850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the results are not float numbers, but intergers 0 and 1\n",
    "results = [int(x) for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your prediction results to 'upload_predictions.txt' and upload that later\n",
    "with open('upload_predictions.txt', 'w', encoding = 'utf-8') as fp:\n",
    "    for x in results:\n",
    "        fp.write(str(x) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
