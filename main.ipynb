{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 8)\n",
      "(3747,)\n",
      "(3747, 8)\n"
     ]
    }
   ],
   "source": [
    "###  Load data\n",
    "\n",
    "def read_csv(file):\n",
    "    with open(file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        line_count = 0\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            if line_count == 0:\n",
    "                titles = row\n",
    "            else:\n",
    "                rows.append(row)\n",
    "            line_count += 1\n",
    "    rows_int = np.array([[int(r) for r in row] for row in rows])\n",
    "    return titles, rows_int\n",
    "        \n",
    "\n",
    "titles, rows_train = read_csv('data/studentsdigits-train.csv')\n",
    "assert titles[-1] == 'Digit' and len(titles) == 9, 'Not train set'\n",
    "X_train = rows_train[:,0:len(titles)-1]\n",
    "Y_train = rows_train[:,-1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "titles, rows_test = read_csv('data/studentsdigits-test.csv')\n",
    "assert len(titles) == 8, 'Not test set'\n",
    "X_test = rows_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def sanitize_param_name(param_name):\n",
    "    return (\n",
    "        param_name.replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\",\", \"_\")\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\"<\", \"\")\n",
    "        .replace(\">\", \"\")\n",
    "        .replace(\"'\", \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MLP model\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        torch.manual_seed(0)  # reproducibility\n",
    "\n",
    "        # self.layers = nn.ModuleDict(\n",
    "        #     OrderedDict(\n",
    "        #         [\n",
    "        #             (\"fc_1\", nn.Linear(in_features=8, out_features=32)),\n",
    "        #             (\"relu_1\", nn.ReLU()),\n",
    "        #             (\"fc_2\", nn.Linear(in_features=32, out_features=16)),\n",
    "        #             (\"relu_2\", nn.ReLU()),\n",
    "        #             (\"fc_3\", nn.Linear(in_features=16, out_features=10)),\n",
    "        #             (\"relu_3\", nn.ReLU()),\n",
    "        #         ]\n",
    "        #     )\n",
    "        # )\n",
    "        # Maybe a little bit deepere rnn\n",
    "        self.rnn = nn.RNN(input_size=2, hidden_size=16, num_layers=3, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=16, out_features=10)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "    def run(self, X_train, Y_train):\n",
    "        kf = KFold(n_splits=10, shuffle=False)\n",
    "        # k-fold cross validation\n",
    "        for fold, (train_index, test_index) in enumerate(\n",
    "            tqdm(kf.split(X_train), total=kf.get_n_splits())\n",
    "        ):\n",
    "            self.train()\n",
    "            x_train_fold, x_evaluate_fold = X_train[train_index], X_train[test_index]\n",
    "            y_train_fold, y_evaluate_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "            x_train_foldTensor = torch.tensor(x_train_fold, dtype=torch.float32).view(\n",
    "                -1, 4, 2\n",
    "            )\n",
    "            y_train_foldTensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
    "            x_evaluate_fold = torch.tensor(x_evaluate_fold, dtype=torch.float32).view(\n",
    "                -1, 4, 2\n",
    "            )\n",
    "            y_evaluate_fold = torch.tensor(y_evaluate_fold, dtype=torch.long)\n",
    "\n",
    "            for epoch in trange(600, desc=f\"Fold {fold+1}\", leave=False):\n",
    "                self.optimizer.zero_grad()\n",
    "                fold_pred = self.forward(x_train_foldTensor)\n",
    "                loss = self.lossFunction(fold_pred, y_train_foldTensor)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Evaluate using this fold\n",
    "            self.eval()\n",
    "            fold_evaluate_pred = self.forward(x_evaluate_fold)\n",
    "\n",
    "            # Metrics\n",
    "            acc = accuracy_score(y_evaluate_fold, fold_evaluate_pred.argmax(dim=1))\n",
    "            lossItem = loss.item()\n",
    "            print(f\"Epoch: {epoch}, Loss: {lossItem}, Accuracy: {acc}\")\n",
    "        # Save the model\n",
    "        torch.save(self.state_dict(), sanitize_param_name(f'./model-{time.strftime(\"%Y%m%d-%H%M%S\")}.pth'))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.eval()\n",
    "        x_testTensor = torch.tensor(X_test, dtype=torch.float32).view(-1, 4, 2)\n",
    "        return self.forward(x_testTensor).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:39,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.2347293496131897, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:08<00:34,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.07039616256952286, Accuracy: 0.14933333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:12<00:30,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.05680359899997711, Accuracy: 0.7413333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:17<00:25,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.031084025278687477, Accuracy: 0.8986666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:21<00:21,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.028172379359602928, Accuracy: 0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:25<00:16,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.01786681078374386, Accuracy: 0.9493333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:29<00:12,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.010866211727261543, Accuracy: 0.8853333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:33<00:08,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.0050071836449205875, Accuracy: 0.9278074866310161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:38<00:04,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.006776359397917986, Accuracy: 0.9598930481283422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:42<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.004412205424159765, Accuracy: 0.893048128342246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = Model()\n",
    "model.run(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 1, 0,  ..., 5, 1, 7])\n",
      "torch.Size([3747])\n"
     ]
    }
   ],
   "source": [
    "### You code\n",
    "prediction = model.predict(X_test)\n",
    "print(prediction)\n",
    "print(prediction.shape)\n",
    "\n",
    "# Save prediction to text file and each line a number\n",
    "# np.savetxt('upload_predictions.txt', prediction.numpy(), fmt='%d')\n",
    "Y_test = prediction.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "### Save prediction results\n",
    "assert len(Y_test) == len(X_test), 'sizes dont match'\n",
    "with open('upload_predictions.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(str(y) for y in Y_test))\n",
    "print('SAVED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecs271",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
