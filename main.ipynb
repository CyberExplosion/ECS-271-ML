{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 8)\n",
      "(3747,)\n",
      "(3747, 8)\n"
     ]
    }
   ],
   "source": [
    "###  Load data\n",
    "\n",
    "def read_csv(file):\n",
    "    with open(file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        line_count = 0\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            if line_count == 0:\n",
    "                titles = row\n",
    "            else:\n",
    "                rows.append(row)\n",
    "            line_count += 1\n",
    "    rows_int = np.array([[int(r) for r in row] for row in rows])\n",
    "    return titles, rows_int\n",
    "        \n",
    "\n",
    "titles, rows_train = read_csv('data/studentsdigits-train.csv')\n",
    "assert titles[-1] == 'Digit' and len(titles) == 9, 'Not train set'\n",
    "X_train = rows_train[:,0:len(titles)-1]\n",
    "Y_train = rows_train[:,-1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "titles, rows_test = read_csv('data/studentsdigits-test.csv')\n",
    "assert len(titles) == 8, 'Not test set'\n",
    "X_test = rows_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MLP model\n",
    "\n",
    "class MLP (nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        torch.manual_seed(0)    # reproducibility\n",
    "\n",
    "        self.layers = nn.ModuleDict(OrderedDict([\n",
    "            ('fc_1', nn.Linear(in_features=8, out_features=32)),\n",
    "            ('relu_1', nn.ReLU()),\n",
    "            ('fc_2', nn.Linear(in_features=32, out_features=16)),\n",
    "            ('relu_2', nn.ReLU()),\n",
    "            ('fc_3', nn.Linear(in_features=16, out_features=10)),\n",
    "            ('relu_3', nn.ReLU()),\n",
    "        ]))\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, X_train, Y_train):\n",
    "        self.training = True\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=False)\n",
    "        # k-fold cross validation\n",
    "        for fold, (train_index, test_index) in enumerate(tqdm(kf.split(X_train), total=kf.get_n_splits())):\n",
    "            x_train_fold, x_evaluate_fold = X_train[train_index], X_train[test_index]\n",
    "            y_train_fold, y_evaluate_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "            for epoch in trange(1000, desc=f'Fold {fold+1}', leave=False):\n",
    "                self.optimizer.zero_grad()\n",
    "                fold_pred = self.forward(torch.FloatTensor(np.array(x_train_fold)))\n",
    "                fold_true = torch.LongTensor(np.array(y_train_fold))\n",
    "                loss = self.lossFunction(fold_pred, fold_true)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Evaluate using this fold\n",
    "            fold_evaluate_pred = self.forward(torch.FloatTensor(np.array(x_evaluate_fold)))\n",
    "            fold_evaluate_true = torch.LongTensor(np.array(y_evaluate_fold))\n",
    "\n",
    "            # Metrics\n",
    "            acc = accuracy_score(fold_evaluate_true, fold_evaluate_true)\n",
    "            lossItem = loss.item()\n",
    "            print(f'Epoch: {epoch}, Loss: {lossItem}, Accuracy: {acc}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:10,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999, Loss: 0.3554541766643524, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:05<00:07,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999, Loss: 0.35365748405456543, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:07<00:05,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999, Loss: 0.3462342917919159, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:10<00:02,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999, Loss: 0.03273861110210419, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999, Loss: 0.2950341999530792, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = MLP()\n",
    "model.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You code\n",
    "\n",
    "### The predictions of test set: Y_test\n",
    "Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "sizes dont match",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Save prediction results\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(Y_test) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_test), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msizes dont match\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupload_predictions.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m      4\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m Y_test))\n",
      "\u001b[1;31mAssertionError\u001b[0m: sizes dont match"
     ]
    }
   ],
   "source": [
    "### Save prediction results\n",
    "assert len(Y_test) == len(X_test), 'sizes dont match'\n",
    "with open('upload_predictions.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(str(y) for y in Y_test))\n",
    "print('SAVED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecs271",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
