{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 8)\n",
      "(3747,)\n",
      "(3747, 8)\n"
     ]
    }
   ],
   "source": [
    "###  Load data\n",
    "\n",
    "def read_csv(file):\n",
    "    with open(file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        line_count = 0\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            if line_count == 0:\n",
    "                titles = row\n",
    "            else:\n",
    "                rows.append(row)\n",
    "            line_count += 1\n",
    "    rows_int = np.array([[int(r) for r in row] for row in rows])\n",
    "    return titles, rows_int\n",
    "        \n",
    "\n",
    "titles, rows_train = read_csv('data/studentsdigits-train.csv')\n",
    "assert titles[-1] == 'Digit' and len(titles) == 9, 'Not train set'\n",
    "X_train = rows_train[:,0:len(titles)-1]\n",
    "Y_train = rows_train[:,-1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "titles, rows_test = read_csv('data/studentsdigits-test.csv')\n",
    "assert len(titles) == 8, 'Not test set'\n",
    "X_test = rows_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MLP model\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        torch.manual_seed(0)  # reproducibility\n",
    "\n",
    "        # self.layers = nn.ModuleDict(\n",
    "        #     OrderedDict(\n",
    "        #         [\n",
    "        #             (\"fc_1\", nn.Linear(in_features=8, out_features=32)),\n",
    "        #             (\"relu_1\", nn.ReLU()),\n",
    "        #             (\"fc_2\", nn.Linear(in_features=32, out_features=16)),\n",
    "        #             (\"relu_2\", nn.ReLU()),\n",
    "        #             (\"fc_3\", nn.Linear(in_features=16, out_features=10)),\n",
    "        #             (\"relu_3\", nn.ReLU()),\n",
    "        #         ]\n",
    "        #     )\n",
    "        # )\n",
    "        # Maybe a little bit deepere rnn\n",
    "        self.rnn = nn.RNN(input_size=2, hidden_size=16, num_layers=3, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=16, out_features=10)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # for layer in self.layers.values():\n",
    "        #     x = layer(x)\n",
    "        # return x\n",
    "\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "    def run(self, X_train, Y_train):\n",
    "        kf = KFold(n_splits=10, shuffle=False)\n",
    "        # k-fold cross validation\n",
    "        for fold, (train_index, test_index) in enumerate(\n",
    "            tqdm(kf.split(X_train), total=kf.get_n_splits())\n",
    "        ):\n",
    "            self.train()\n",
    "            x_train_fold, x_evaluate_fold = X_train[train_index], X_train[test_index]\n",
    "            y_train_fold, y_evaluate_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "            x_train_foldTensor = torch.tensor(x_train_fold, dtype=torch.float32).view(\n",
    "                -1, 4, 2\n",
    "            )\n",
    "            # x_train_foldTensor = torch.tensor(x_train_fold, dtype=torch.float32)\n",
    "            y_train_foldTensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
    "            x_evaluate_fold = torch.tensor(x_evaluate_fold, dtype=torch.float32).view(\n",
    "                -1, 4, 2\n",
    "            )\n",
    "            # x_evaluate_fold = torch.tensor(x_evaluate_fold, dtype=torch.float32)\n",
    "            y_evaluate_fold = torch.tensor(y_evaluate_fold, dtype=torch.long)\n",
    "\n",
    "            # print(f'Shape of x_train_foldTensor is: {x_train_foldTensor.shape}')\n",
    "            # print(f'Value of of one entry in x_train_foldTensor is: {x_train_foldTensor[0]}')\n",
    "            for epoch in trange(500, desc=f\"Fold {fold+1}\", leave=False):\n",
    "                self.optimizer.zero_grad()\n",
    "                fold_pred = self.forward(x_train_foldTensor)\n",
    "                # fold_true = torch.LongTensor(np.array(y_train_fold))\n",
    "                loss = self.lossFunction(fold_pred, y_train_foldTensor)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Evaluate using this fold\n",
    "            self.eval()\n",
    "            fold_evaluate_pred = self.forward(x_evaluate_fold)\n",
    "            # fold_evaluate_true = torch.LongTensor(np.array(y_evaluate_fold))\n",
    "\n",
    "            # Metrics\n",
    "            acc = accuracy_score(y_evaluate_fold, fold_evaluate_pred.argmax(dim=1))\n",
    "            lossItem = loss.item()\n",
    "            print(f\"Epoch: {epoch}, Loss: {lossItem}, Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:31,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.30239948630332947, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:07<00:28,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.09637830406427383, Accuracy: 0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:10<00:24,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.07857978343963623, Accuracy: 0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:14<00:21,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.04639371857047081, Accuracy: 0.8773333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:17<00:17,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.040839068591594696, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:21<00:14,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.028596315532922745, Accuracy: 0.9306666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:24<00:10,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.018339045345783234, Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:28<00:07,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.009206902235746384, Accuracy: 0.9037433155080213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:31<00:03,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.01045581791549921, Accuracy: 0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Loss: 0.007662969175726175, Accuracy: 0.8796791443850267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = Model()\n",
    "model.run(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You code\n",
    "\n",
    "### The predictions of test set: Y_test\n",
    "Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "sizes dont match",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Save prediction results\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(Y_test) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_test), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msizes dont match\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupload_predictions.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m      4\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m Y_test))\n",
      "\u001b[1;31mAssertionError\u001b[0m: sizes dont match"
     ]
    }
   ],
   "source": [
    "### Save prediction results\n",
    "assert len(Y_test) == len(X_test), 'sizes dont match'\n",
    "with open('upload_predictions.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(str(y) for y in Y_test))\n",
    "print('SAVED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecs271",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
