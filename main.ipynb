{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 8)\n",
      "(3747,)\n",
      "(3747, 8)\n"
     ]
    }
   ],
   "source": [
    "###  Load data\n",
    "\n",
    "def read_csv(file):\n",
    "    with open(file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        line_count = 0\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            if line_count == 0:\n",
    "                titles = row\n",
    "            else:\n",
    "                rows.append(row)\n",
    "            line_count += 1\n",
    "    rows_int = np.array([[int(r) for r in row] for row in rows])\n",
    "    return titles, rows_int\n",
    "        \n",
    "\n",
    "titles, rows_train = read_csv('data/studentsdigits-train.csv')\n",
    "assert titles[-1] == 'Digit' and len(titles) == 9, 'Not train set'\n",
    "X_train = rows_train[:,0:len(titles)-1]\n",
    "Y_train = rows_train[:,-1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "titles, rows_test = read_csv('data/studentsdigits-test.csv')\n",
    "assert len(titles) == 8, 'Not test set'\n",
    "X_test = rows_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def sanitize_param_name(param_name):\n",
    "    return (\n",
    "        param_name.replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\",\", \"_\")\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\"<\", \"\")\n",
    "        .replace(\">\", \"\")\n",
    "        .replace(\"'\", \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the MLP model\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        torch.manual_seed(0)  # reproducibility\n",
    "\n",
    "        # self.layers = nn.ModuleDict(\n",
    "        #     OrderedDict(\n",
    "        #         [\n",
    "        #             (\"fc_1\", nn.Linear(in_features=8, out_features=32)),\n",
    "        #             (\"relu_1\", nn.ReLU()),\n",
    "        #             (\"fc_2\", nn.Linear(in_features=32, out_features=16)),\n",
    "        #             (\"relu_2\", nn.ReLU()),\n",
    "        #             (\"fc_3\", nn.Linear(in_features=16, out_features=10)),\n",
    "        #             (\"relu_3\", nn.ReLU()),\n",
    "        #         ]\n",
    "        #     )\n",
    "        # )\n",
    "        # Maybe a little bit deepere rnn\n",
    "        self.rnn = nn.RNN(input_size=2, hidden_size=16, num_layers=4, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=16, out_features=10)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "    def run(self, X_train, Y_train):\n",
    "        kf = KFold(n_splits=10, shuffle=False)\n",
    "        # k-fold cross validation\n",
    "        for fold, (train_index, test_index) in enumerate(\n",
    "            tqdm(kf.split(X_train), total=kf.get_n_splits())\n",
    "        ):\n",
    "            self.train()\n",
    "            x_train_fold, x_evaluate_fold = X_train[train_index], X_train[test_index]\n",
    "            y_train_fold, y_evaluate_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "            x_train_foldTensor = torch.tensor(x_train_fold, dtype=torch.float32).view(\n",
    "                -1, 4, 2\n",
    "            )\n",
    "            y_train_foldTensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
    "            x_evaluate_fold = torch.tensor(x_evaluate_fold, dtype=torch.float32).view(\n",
    "                -1, 4, 2\n",
    "            )\n",
    "            y_evaluate_fold = torch.tensor(y_evaluate_fold, dtype=torch.long)\n",
    "\n",
    "            for epoch in trange(600, desc=f\"Fold {fold+1}\", leave=False):\n",
    "                self.optimizer.zero_grad()\n",
    "                fold_pred = self.forward(x_train_foldTensor)\n",
    "                loss = self.lossFunction(fold_pred, y_train_foldTensor)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Evaluate using this fold\n",
    "            self.eval()\n",
    "            fold_evaluate_pred = self.forward(x_evaluate_fold)\n",
    "\n",
    "            # Metrics\n",
    "            acc = accuracy_score(y_evaluate_fold, fold_evaluate_pred.argmax(dim=1))\n",
    "            lossItem = loss.item()\n",
    "            print(f\"Epoch: {epoch}, Loss: {lossItem}, Accuracy: {acc}\")\n",
    "        # Save the model\n",
    "        torch.save(self.state_dict(), sanitize_param_name(f'./model-{time.strftime(\"%Y%m%d-%H%M%S\")}.pth'))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.eval()\n",
    "        x_testTensor = torch.tensor(X_test, dtype=torch.float32).view(-1, 4, 2)\n",
    "        return self.forward(x_testTensor).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:49,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.22937868535518646, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:10<00:43,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.07700520753860474, Accuracy: 0.11466666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:16<00:37,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.059558358043432236, Accuracy: 0.7413333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:21<00:32,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.032874371856451035, Accuracy: 0.8986666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:26<00:26,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.02408190630376339, Accuracy: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:32<00:21,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.01330341212451458, Accuracy: 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:37<00:16,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.008724967017769814, Accuracy: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:42<00:10,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.0056118411011993885, Accuracy: 0.9385026737967914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:48<00:05,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.004290617536753416, Accuracy: 0.9732620320855615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:53<00:00,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.0025399052537977695, Accuracy: 0.9331550802139037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = Model()\n",
    "model.run(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 1, 0,  ..., 5, 1, 7])\n",
      "torch.Size([3747])\n"
     ]
    }
   ],
   "source": [
    "### You code\n",
    "prediction = model.predict(X_test)\n",
    "print(prediction)\n",
    "print(prediction.shape)\n",
    "\n",
    "# Save prediction to text file and each line a number\n",
    "# np.savetxt('upload_predictions.txt', prediction.numpy(), fmt='%d')\n",
    "Y_test = prediction.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "### Save prediction results\n",
    "assert len(Y_test) == len(X_test), 'sizes dont match'\n",
    "with open('upload_predictions.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(str(y) for y in Y_test))\n",
    "print('SAVED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecs271",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
