Please limit your answer to every question to five sentences or less.

Q1: Train a machine learning classifier, please specify i) your classification method, and ii) the loss function for multi-class classification.
I choose a simple shallow RNN as a machine learning classifier. For loss function, I use Cross-Entropy for multi-class labeling.

Q2: Please describe a method to estimate your performance before testing on the test set.
I trained the model using k-fold cross-validation, with the k-fold split of 10 giving the best performance. After every fold, I check the model evaluation accuracy as well as their loss. I keep a record of every epoch using the tensorboard library as well as keep track of each fold performance using a simple .csv file. Since the model training accuracy improves over time and the validation accuracy also increases over time, I'm highly confident that the model is learning what I want it to learn. The training loss and validation loss also went down during training so I know that the model also achieved a high level of confidence.

Q3: Please list the key hyperparameter values to consider, e.g., the choice of the optimizer (e.g., Adam, SGD), learning rate, batch size, and possibly the architecture of the machine learning classifier.
The number of running epochs per fold, the number of fold splits, the learning rate, the batch size for loading data from the training folds, and the model itself (MLP, CNN, RNN). For the optimizer, I've only tested with ADAM, but since it gives very good performance I've been sticking with it. For the loss function, it's CrossEntropyLoss due to classifying multiple labels.

Q4: Please list the key Python packages used in this assignment.
Pytorch, Scikit-learn, tensorboard, pandas, tqdm, NumPy

Q5: If applicable, discuss any other methods attempted besides the one submitted, along with their outcomes and reasons for not choosing them.
I began with a simple MLP, however, I noticed a very strong training accuracy, but once the validation fold came, the accuracy and loss for the validation fold did not improve in any way. This tells me that the model is overfitting to a particular training fold and generalizes well enough for new data.
I was then thinking that maybe regularization would help, but figured the problem its due to the type of data we working with would not work well with simple MLP. I then tried to use a simple shallow CNN model because each x,y coordinate is a pixel of an image with a gray scale value of 1. However, this also does not give good performance. I then use RNN due to the sequential nature of the data with subsequent x,y coordinates related to one another.